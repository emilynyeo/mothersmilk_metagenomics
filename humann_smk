import os
import pandas as pd
from os.path import join as pj
from os.path import split
from src.snake_utils import read_samples_full, read_sample_names, get_partition, get_mem, get_runtime, get_threads, get_slurm_extra
from types import SimpleNamespace
#config = SimpleNamespace(**config)

# Read sample names from "sample_names.txt" made using src/sample_names.py prior to snakemake
samples=read_samples_full(f"{config['sample_IDs']}")
# Identify duplicates
duplicate_samples = [sample for sample in set(samples) if samples.count(sample) > 1]

rule all:
    input:
        expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz", sample=samples),
    # humann :
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_genefamilies.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathabundance.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathcoverage.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_humann_temp/{{sample}}.trimmed_1P.cleancombined_metaphlan_bugs_list.tsv", sample=samples)

rule concatenate:
    input:
        FORWARD=expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz", sample=samples),
        REVERSE=expand(f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz", sample=samples)
    output:
        catfile=f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz"
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    shell:
        """
        if [ ! -f {output.catfile} ]; then
            cat {input.FORWARD} {input.REVERSE} > {output.catfile}
        else
            echo 'Combined file {output.catfile} already exists. Skipping combination.'
        fi
        """

rule humann:
    input:
        catfile=f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz"
    output:
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_genefamilies.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathabundance.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathcoverage.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_humann_temp/{{sample}}.trimmed_1P.cleancombined_metaphlan_bugs_list.tsv"
    conda:
        "humann_env"
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    params:
        humann_out=config['humann_out'],
        protein_db=config['uniref_db'],
        nucleotide_db=config['chocophlan_db']
    shell:
        """
        fpathc={input.catfile}
        humann --protein-database "{params.protein_db}" \
            --nucleotide-database "{params.nucleotide_db}" \
            --input "$fpathc" \
            --output "{params.humann_out}" 
        
        rm {input.catfile}
        """
