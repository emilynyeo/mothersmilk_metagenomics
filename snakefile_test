import os
import pandas as pd
from os.path import join as pj
from os.path import split
from src.snake_utils import read_samples_full, read_sample_names, get_partition, get_mem, get_runtime, get_threads, get_slurm_extra
from types import SimpleNamespace
#config = SimpleNamespace(**config)


# Read sample names from "sample_names.txt" made using src/sample_names.py prior to snakemake
samples=read_samples_full(f"{config['sample_IDs']}")
# Identify duplicates
duplicate_samples = [sample for sample in set(samples) if samples.count(sample) > 1]

rule all:
    # test output:
    input:
    #    expand(f"{config['out_dir']}test/{{sample}}_1.txt", sample=samples),
    #    expand(f"{config['out_dir']}test/{{sample}}_2.txt", sample=samples),
    # fastqc1 output:
    #    expand(f"{config['fastqc1']}{{sample}}_1_fastqc.zip", sample=samples),
    #    expand(f"{config['fastqc1']}{{sample}}_2_fastqc.zip", sample=samples),
    # trimming:
        expand(f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_1P", sample=samples),
        expand(f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_2P", sample=samples),
    # hostile:
        expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz", sample=samples),
        expand(f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz", sample=samples),
    # fastqc2:
    #    expand(f"{config['fastqc2']}{{sample}}.trimmed_1P.clean_1_fastqc.zip", sample=samples),
    #    expand(f"{config['fastqc2']}{{sample}}.trimmed_2P.clean_2_fastqc.zip", sample=samples),
    # catfiles:
        expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz", sample=samples),
    # humann :
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_genefamilies.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathabundance.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathcoverage.tsv", sample=samples),
        expand(f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_humann_temp/{{sample}}.trimmed_1P.cleancombined_metaphlan_bugs_list.tsv", sample=samples)

rule test:
    input:
        F=f"{config['data_dir']}{{sample}}_1.fq.gz",
        R=f"{config['data_dir']}{{sample}}_2.fq.gz"
    output:
        f"{config['out_dir']}test/{{sample}}_1.txt",
        f"{config['out_dir']}test/{{sample}}_2.txt"
    params:
        out=config['out_dir']
    shell:
        """
        mkdir -p {params.out}test/
        basename {input.F} > {params.out}test/'{wildcards.sample}'_1.txt
        basename {input.R} > {params.out}test/'{wildcards.sample}'_2.txt
        """

rule fastqc1:
    input:
        FORWARD=expand(f"{config['data_dir']}{{sample}}_1.fq.gz", sample=samples),
        REVERSE=expand(f"{config['data_dir']}{{sample}}_2.fq.gz", sample=samples)
    output:
        directory(f"{config['fastqc1']}{{sample}}"),
        f"{config['fastqc1']}{{sample}}_1_fastqc.zip",
        f"{config['fastqc1']}{{sample}}_2_fastqc.zip"
    conda:
        "qc_env_with_fastqc_and_multiqc"
    resources:
        mem_mb=2000, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    params:
        fastqc1=config['fastqc1']
    shell:
        """
        mkdir -p {params.fastqc1}
        touch {params.fastqc1}failures.txt
        mkdir -p {output}
        fastqc --threads 1 {input.FORWARD} {input.REVERSE} -o {output} \
            || echo {wildcards.sample} >> {params.fastqc1}failures.txt
        """

rule trim_and_adapters:
    input:
        FORWARD=expand(f"{config['data_dir']}{{sample}}_1.fq.gz", sample=samples),
        REVERSE=expand(f"{config['data_dir']}{{sample}}_2.fq.gz", sample=samples)
    output:
        directory(f"{config['trim_adapters']}{{sample}}"),
        f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_1P",
        f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_2P"
    conda:
        "trimmomatic_env"
    resources:
        mem_mb=2000, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    params:
        trimout=config['trim_adapters'],
        flops=config['flops'],
        min=config['min_readlen'],
        lead=config['leading'],
        trail=config['trailing'],
        swindow=config['swindow'],
        adapters=config['adapters']
    shell:
        """
        touch {params.flops}
        mkdir -p {params.trimout}{wildcards.sample}
        trimmomatic PE -threads 1 \
            -trimlog {params.trimout}{wildcards.sample}/{wildcards.sample}.trimlog \
            -summary {params.trimout}{wildcards.sample}/{wildcards.sample}.trim.log \
            -validatePairs {input.FORWARD} {input.REVERSE} \
            -baseout {params.trimout}{wildcards.sample}/{wildcards.sample}.trimmed \
            ILLUMINACLIP:{params.adapters} SLIDINGWINDOW:{params.swindow} LEADING:{params.lead} TRAILING:{params.trail} MINLEN:{params.min} \
            || echo {wildcards.sample} >> {params.flops}

        #mv {params.trimout}{wildcards.sample}/{wildcards.sample}.trimmed_1P {params.trimout}{wildcards.sample}/{wildcards.sample}.trimmed.R1.fq
        #mv {params.trimout}{wildcards.sample}/{wildcards.sample}.trimmed_2P {params.trimout}{wildcards.sample}/{wildcards.sample}.trimmed.R2.fq
        echo 'completed adapter trimming of {wildcards.sample}'
        """ 

rule hostile:
    input:
        file_r1=expand(f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_1P", sample=samples),#        file_r2=expand(f"{config['trim_adapters']}{{sample}}/{{sample}}.trimmed_2P", sample=samples)
    output:
        f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz",
        f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz"
    params:
        done=config['hostile_out']
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    conda:
        "hostile"
    shell:
        """
        mkdir {params.done}
        cd {params.done}
        hostile clean --fastq1 '$file_r1' --fastq2 '$file_r2'
        """

rule fastqc2:
    input:
        FORWARD=expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz", sample=samples),
        REVERSE=expand(f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz", sample=samples)
    output:
        directory(f"{config['fastqc2']}{{sample}}"),
        f"{config['fastqc2']}{{sample}}.trimmed_1P.clean_1_fastqc.zip",
        f"{config['fastqc2']}{{sample}}.trimmed_2P.clean_2_fastqc.zip"
    conda:
        "qc_env_with_fastqc_and_multiqc"
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    params:
        fastqc2=config['fastqc2']
    shell:
        """
        mkdir -p {params.fastqc2}
        touch {params.fastqc2}failures.txt
        mkdir -p {output}
        fastqc --threads 1 {input.FORWARD} {input.REVERSE} -o {output} \
            || echo {wildcards.sample} >> {params.fastqc2}failures.txt
        """

rule concatenate:
    input:
        FORWARD=expand(f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz", sample=samples),
        REVERSE=expand(f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz", sample=samples)
    output:
        catfile=f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz"
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    shell:
        """
        if [ ! -f {output.catfile} ]; then
            cat {input.FORWARD} {input.REVERSE} > {output.catfile}
        else
            echo 'Combined file {output.catfile} already exists. Skipping combination.'
        fi
        """

rule humann:
    input:
        catfile=f"{config['hostile_out']}{{sample}}.trimmed_1P.cleancombined.fastq.gz"
    output:
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_genefamilies.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathabundance.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_pathcoverage.tsv",
        f"{config['humann_out']}{{sample}}.trimmed_1P.cleancombined_humann_temp/{{sample}}.trimmed_1P.cleancombined_metaphlan_bugs_list.tsv"
    conda:
        "humann_env"
    resources:
        mem_mb=200, # MB
        partition="amilan",
        slurm_extra="--nodes=1 --qos=normal --time=10:00:00 --ntasks=1 --mail-type=ALL --mail-user=emye7956@colorado.edu"
    threads: 1
    params:
        humann_out=config['humann_out']
        protein_db=config['uniref_db']
        nucleotide_db=config['chocophlan_db']
    shell:
        """
        fpathc={input.catfile}
        humann --protein-database "{params.protein_db}" \
            --nucleotide-database "{params.nucleotide_db}" \
            --input "$fpathc" \
            --output "{params.humann_out}"
        """

rule kraken_process:
    input:
        forward=f"{config['hostile_out']}{{sample}}.trimmed_1P.clean_1.fastq.gz",
        reverse=f"{config['hostile_out']}{{sample}}.trimmed_2P.clean_2.fastq.gz"
    output:
        output_report=f"{config['kraken_out']}{{sample}}.report.txt",
        output_txt=f"{config['kraken_out']}{{sample}}.output.txt"
    params:
        processed_files=config['processed_kraken']
        kraken_db=config['kraken_db']
    shell:
        """
        base=$(basename {input.forward} .trimmed_1P.clean_1.fastq.gz)
        base=${{base%%_*}}
        suffix=$(echo {input.forward} | cut -d'_' -f2-4 | sed 's/\.trimmed//')
        echo "${{base}}_${{suffix}}"

        if ! grep -q "${{base}}" {params.processed_files}; then
            echo "Running sample ${{base}}"
            kraken2 --db {params.kraken_db} \\
                --threads 40 \\
                --output {output.output_txt} \\
                --report {output.output_report} \\
                --report-zero-counts \\
                --gzip-compressed \\
                --use-names \\
                --paired {input.forward} {input.reverse}

            echo "${{base}}" >> {params.processed_files}
        else
            echo "Skipping sample ${{base}} (already processed)"
        fi
        """
#rule braken:

        