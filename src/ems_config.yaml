
### modify these paths for each computer setup each time

main_dir:
  /pl/active/ADOR/projects/mothersmilk/mothersmilk_metagenomics/
data_dir:
  /pl/active/ADOR/projects/mothersmilk/chla_data_transfer/fastq/fastq/
out_dir:
  /pl/active/ADOR/projects/mothersmilk/mothersmilk_metagenomics/doc/
sample_IDs:
  /pl/active/ADOR/projects/mothersmilk/mothersmilk_metagenomics/sample_names_long.txt

# Project name
PROJ: test

# Metadata file
METADATA: doc/mothersmilk_metadata.csv
fwd_reads_path: forward_reads
rev_reads_path: reverse_reads

################################################
### Fastqc ###
fastqc1:
  /pl/active/ADOR/projects/mothersmilk/fastqc1/fastqc1_output_new/

################################################
### TRIMMOMATIC ADAPTER AND QUALITY TRIMMING ###
trim_adapters:
  /pl/active/ADOR/projects/mothersmilk/trimming/noadapters_trim_output_new/test/
# minimum read length after trimming
min_readlen: 50
# the minimum quality for the start of a read. If it's below this quality, trim that base pair
leading: 20
# the minimum quality for the end of a read. If it's below this quality, trim that base pair
trailing: 20
# Sliding window is ...
swindow: 4:20
# The adapter sequences to remove
adapters:
  /pl/active/ADOR/projects/mothersmilk/trimming/adapters.fasta:2:30:10
flops:
  /pl/active/ADOR/projects/mothersmilk/trimming/noadapters_trim_output_new/failures_test.txt


############################
### Hostile host read removal ###
# Database for host read removal
# Current supported options include:
# - human-t2t-hla
# - human-t2t-hla-argos985
# - filepath to an already downloaded and bowtie2-indexed database 
#   (with no .bt1, .bt2 etc file extensions in this argument)
hostile_db: human-t2t-hla-argos985
# Where to download a database for hostile (if applicable)
loc_for_hostile_db_download: data
# Where you want the output to go:
hostile_out:
  /pl/active/ADOR/projects/mothersmilk/hostile/all/test/


#################################
### HUMAnN BioBakery pipeline ###

# Path to MetaPhlan bowtie database (step 1 of HUMAnN)
metaphlan_bowtie_db: data/metaphlan_db/

# Paths to Chocophlan and UniRef databases for HUMAnN
# If these aren't already downloaded, HoMi will download them
chocophlan_db: data/humann_dbs/chocophlan
uniref_db: data/humann_dbs/uniref
utility_mapping_db: data/humann_dbs/utility_mapping 


########################
### Kraken + Bracken ###
kraken_db: data/kraken2_db

################################
### Resources ###
# Rules will use the default resources outlined for them in the snakefile, 
# unless you provide other resource specifications here.
# these should be formatted as <rule_name>_<resource>
# examples:
# rule_name_partition: new_partition
# rule_name_mem_mb: 10000 # (10 GB)
# rule_name_runtime: 600 # (10 hours)
# rule_name_threads: 8 

# fastq_rule
fastqc_partition: amilan
fastqc_runtime: 600 # 10 hours
fastqc_threads: 10
fastqc_mem_mb: 50000

################################
### Partition ###
# This is an optional resource parameter to map partitions named: 
# "short" --> default_short_partition_name
# "long" --> default_long_partition_name
# If nothing is here, nothing will be done

default_short_partition_name: amilan
default_long_partition_name: long

################################
### Slurm Extras ###
# For cluster use, users may want to pass slurm extra parameters
# This can be done using default_slurm_extra, which will serve as a default for all steps
# or by using <rule_name>_slurm_extra, which provides rule-specific slurm extra parameters.
# Rule-specific parameters are prioritized over default params.
# These parameters should be a space-separated list, formatted as
# <slurm_long_name>=<parameter> <slurm_long_name_2>=<parameter_2>
# for all rules:
default_slurm_extra: email=emye7956@colorado.edu

# for specific rules:

# bbmap_host_slurm_extra: qos=long email=sample_email@colorado.edu
# All rules would receive the email param, 
# and the bbmap host rule would also receive the qos param
